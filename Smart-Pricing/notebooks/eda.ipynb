{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1f1cf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Quick EDA Notebook for Hackathon\n",
    "# -------------------------------\n",
    "\n",
    "# Step 1: Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Step 3: Basic info\n",
    "print(\"Shape of data:\", train.shape)\n",
    "print(\"\\nColumns:\", train.columns.tolist())\n",
    "\n",
    "# Step 4: Describe price column\n",
    "if 'price' in train.columns:\n",
    "    print(\"\\n--- Price Statistics ---\")\n",
    "    display(train['price'].describe())\n",
    "\n",
    "# Step 5: Check word counts in catalog_content (if exists)\n",
    "if 'catalog_content' in train.columns:\n",
    "    train['word_count'] = train['catalog_content'].fillna(\"\").apply(lambda x: len(x.split()))\n",
    "    print(\"\\n--- Word Count Statistics ---\")\n",
    "    display(train['word_count'].describe())\n",
    "\n",
    "    # Word count distribution\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(train['word_count'], bins=50)\n",
    "    plt.title(\"Catalog Content Word Count Distribution\")\n",
    "    plt.xlabel(\"Word Count\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# Step 6: Check percentage of missing image_link\n",
    "if 'image_link' in train.columns:\n",
    "    missing_image_pct = train['image_link'].isna().mean() * 100\n",
    "    print(f\"\\n% Missing image_link: {missing_image_pct:.2f}%\")\n",
    "\n",
    "# Step 7: Plot price histogram (log scale)\n",
    "if 'price' in train.columns:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(train['price'], bins=50)\n",
    "    plt.xscale('log')\n",
    "    plt.title(\"Price Distribution (Log Scale)\")\n",
    "    plt.xlabel(\"Price (log)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# Step 8: Correlation between word count and price\n",
    "if 'catalog_content' in train.columns and 'price' in train.columns:\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.scatterplot(x=np.log1p(train['word_count']), y=np.log1p(train['price']))\n",
    "    plt.title(\"Word Count vs Price (log-log)\")\n",
    "    plt.xlabel(\"log(Word Count + 1)\")\n",
    "    plt.ylabel(\"log(Price + 1)\")\n",
    "    plt.show()\n",
    "\n",
    "# Step 9: Inspect some catalog_content examples\n",
    "if 'catalog_content' in train.columns:\n",
    "    print(\"\\n--- Sample catalog_content ---\")\n",
    "    for text in train['catalog_content'].dropna().head(3):\n",
    "        print(\"\\n\", text[:400], \"...\")\n",
    "\n",
    "# Step 10: Build regex for 'ipq' (or any token of interest)\n",
    "if 'catalog_content' in train.columns:\n",
    "    sample_texts = train['catalog_content'].dropna().head(10).tolist()\n",
    "    pattern = re.compile(r\"\\bipq[-\\s]?\\d+\\b\", flags=re.IGNORECASE)\n",
    "    print(\"\\n--- Example matches for 'ipq' pattern ---\")\n",
    "    for text in sample_texts:\n",
    "        matches = pattern.findall(text)\n",
    "        if matches:\n",
    "            print(matches)\n",
    "\n",
    "# Step 11: Look at top brands/tokens if present\n",
    "if 'brand' in train.columns:\n",
    "    print(\"\\n--- Top Brands ---\")\n",
    "    display(train['brand'].value_counts().head(10))\n",
    "\n",
    "# Or try tokenizing catalog_content\n",
    "if 'catalog_content' in train.columns:\n",
    "    from collections import Counter\n",
    "    tokens = []\n",
    "    for text in train['catalog_content'].dropna():\n",
    "        tokens.extend(re.findall(r'\\b[a-zA-Z]{3,}\\b', text.lower()))\n",
    "    token_counts = Counter(tokens)\n",
    "    print(\"\\n--- Top Tokens ---\")\n",
    "    print(pd.DataFrame(token_counts.most_common(10), columns=['Token', 'Count']))\n",
    "\n",
    "# Step 12: Identify extreme outliers (>99.9 percentile)\n",
    "if 'price' in train.columns:\n",
    "    upper_limit = train['price'].quantile(0.999)\n",
    "    print(f\"\\n99.9th percentile price: {upper_limit:.2f}\")\n",
    "    outliers = train[train['price'] > upper_limit]\n",
    "    print(f\"Number of outliers: {len(outliers)}\")\n",
    "\n",
    "    # Optional: Clip outliers\n",
    "    train['price_clipped'] = np.where(train['price'] > upper_limit, upper_limit, train['price'])\n",
    "    print(\"Created 'price_clipped' column with capped values.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
